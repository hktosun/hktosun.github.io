{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Part 2: Random Coefficient Model </h1>\n",
    "\n",
    "We assumed that everyone has the same taste for each characteristic. However, it's not the case. Additionally, there may be some features of a good that are observable to the consumer, but not to the econometrician. To allow for these, we introduce a new model for the utility (following BLP (1999)):\n",
    "$$\n",
    "\\begin{equation}\n",
    "u_{ijt} = -\\alpha \\frac{p_{jt}}{y_{it}} + x_{jt}\\beta + \\sum_{k=1}^K \\sigma_k v_{ik} x_{jkt} + \\xi_{jt} \\epsilon_{ijt}\n",
    "\\end{equation}\n",
    "$$\n",
    "where $K$ is the number of (observable) characteristics, $\\xi$ is the observable-to-consumer-but-not-to-econometrician component, $v_{ik}$ is a random variable that is distributed standard normal, and $y_{it}$ is the income of individual $i$ at time $t$. \n",
    "\n",
    "The first term in the utility function was $\\log(y_{it}-p_{jt})$ in BLP (1995). But that term is not defined if the price is higher than the income (and in our case, we have some observations where this is true). To eliminate this case, we used the utility function in BLP (1999). \n",
    "\n",
    "Now, define $$\\delta_{jt} \\equiv x_{jt}\\beta + \\xi_{jt} $$ and $$\\mu_{ijt} \\equiv -\\alpha\\frac{p_{jt}}{y_{it}} + \\sum_{k=1}^K \\sigma_k v_{ik} x_{jkt} $$\n",
    "Now, we have the following model:\n",
    "$$\n",
    "\\begin{equation}\n",
    "u_{ijt} = \\delta_{jt} + \\mu_{ijt} + \\epsilon_{ijt}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "So, again, if individual $i$ buys good $j$, it means that good $j$ provides him more utility than any other good $k$, including the outside good. Therefore, we can say that the probability of individual $i$ buying $j$ at year $t$ is equal to \n",
    "\n",
    "$$ \\begin{align}\n",
    "Pr(i \\text{ buys good } j \\text{ in year } t) &= Pr(u_{ijt}> u_{ikt}, \\forall k= {0,1,\\ldots,J_t}, k\\neq j) \\\\\n",
    "&= Pr(\\delta_{jt} + \\mu_{ijt} + \\epsilon_{ijt} > \\delta_{kt} + \\mu_{ikt} + \\epsilon_{ikt}, \\forall k= {0,1,\\ldots,J_t}, k\\neq j)\\\\\n",
    "&= \\frac{\\exp(\\delta_{jt} + \\mu_{ijt})}{1 + \\sum_{k=1}^{J_t} \\exp(\\delta_{kt} + \\mu_{ikt})}\n",
    "\\end{align} \n",
    "$$\n",
    "\n",
    "Assuming that the individuals are distributed with cdf $T$, we can write the probability of good $j$ being sold in year $t$ as\n",
    "$$\n",
    "\\begin{align}\n",
    "Pr(\\text{good } j \\text{ being sold in year } t) &= \\int_i Pr( i \\text{ buys good } j \\text{ in year } t) dT(i) \\\\\n",
    "& = \\int_i \\frac{\\exp(\\delta_{jt} + \\mu_{ijt})}{1 + \\sum_{k=1}^{J_t} \\exp(\\delta_{kt} + \\mu_{ikt})} dT(i) \\\\\n",
    "& \\approx \\frac{1}{ns} \\sum_{i=1}^{ns} \\frac{\\exp(\\delta_{jt} + \\mu_{ijt})}{1 + \\sum_{k=1}^{J_t} \\exp(\\delta_{kt} + \\mu_{ikt})} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Here is how we code this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def s_comp(expdelta0,expmu):\n",
    "    nom = expdelta0 @ np.ones((1,ns)) * expmu\n",
    "    denom = np.dot(A,np.dot(A.T,nom))\n",
    "    frac = nom/(1+denom)\n",
    "    s_computed = (1/ns)*(frac.sum(1))\n",
    "    return(s_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the probabilities, we need $\\delta$'s and $\\mu$'s. However, we don't know what $\\delta$ is. Why? We don't have the data for $\\xi_j$. So, how do we calculate $\\delta_{jt}$? We approximate it numerically.\n",
    "\n",
    "Let's write the following recursion\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\delta^{n+1} = \\delta^{n} + \\log(s^{DATA}) - \\log(s(\\theta)) \\; \\forall n=0,1,2,\\ldots\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $\\theta \\equiv (\\beta,\\alpha,\\sigma)$, and $\\sigma \\equiv (\\sigma_0,\\ldots,\\sigma_k)$. Define $\\theta_B \\equiv (\\alpha,\\sigma)$ to be the set of parameters outside of $\\delta$ for later use.\n",
    "\n",
    "Define $s(\\theta) \\equiv Pr(\\text{good } j \\text{ being sold in year } t)$. So, $\\theta$ is the set of parameters that determines $Pr(\\text{good } j \\text{ being sold in year } t)$. \n",
    "\n",
    "BLP shows that the above equation is a \"contraction\", i.e. for all $\\epsilon>0$, there exists an integer $J_\\epsilon$ such that for all $m>J_\\epsilon$, $||(\\delta^{m+1}-\\delta^{m}||<\\epsilon$. Therefore, we can use the function above to find the \"best\" $\\delta$ that explains the market shares in the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contraction(sigma,alpha):\n",
    "    expdelta0 = deltam\n",
    "    expdelta0.shape = (nrow,1)\n",
    "    draws = v * np.kron(np.ones((ns,1)),sigma)\n",
    "    expmu = (np.exp(np.dot(X,draws.T) - np.dot(price,np.ones((1,ns))) * alpha / y))\n",
    "    dif = 1\n",
    "    it = 0\n",
    "    while(dif > tol and it < 1000):\n",
    "        rat = s_data/s_comp(expdelta0,expmu)\n",
    "        rat.shape = (nrow,1)\n",
    "        expdelta1 = expdelta0 * rat\n",
    "        dif = (abs(expdelta1/expdelta0-1)).max()\n",
    "        expdelta0 = expdelta1\n",
    "        it += 1\n",
    "    return(np.log(expdelta0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For computational speed, I transformed the recursion above by taking exponentials of both sides. What next?\n",
    "\n",
    "## GMM estimation\n",
    "\n",
    "The moment condition we use for the estimation is\n",
    "$$\n",
    "\\begin{equation}\n",
    "E[\\xi\\mid Z] = 0\n",
    "\\end{equation}\n",
    "$$\n",
    "where $Z$ is the instrument matrix. Before going into the GMM objective function, let's first calculate $\\xi$'s.\n",
    "\n",
    "We noted earlier that $ \\delta_{jt} \\equiv x_{jt}\\beta + \\xi_{jt}$. Now that we \"estimated\" $\\delta_{jt}$, we can back out $\\xi_{jt}$. But first, we need $\\beta$. \n",
    "\n",
    "We can get $\\beta$'s by using 2SLS. How? Use the above equation to regress the $\\delta$ we got from the contraction on the product characteristics $X$ and $\\xi$, by using $Z$ as the instrument for $\\xi$. \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{\\beta} = (X^{'} Z \\Phi^{-1} Z^{'} X)^{-1} X^{'} Z \\Phi^{-1} Z^{'} \\delta(\\theta_B)\n",
    "\\end{equation}\n",
    "$$\n",
    "where $\\Phi \\equiv Z^{'}Z$ being the weighting matrix.\n",
    "\n",
    "Then, use $\\hat{\\beta}$ to back out $\\xi$:\n",
    "$$ \\xi_{jt} = \\delta_{jt}(\\theta) - x_{jt}\\beta $$\n",
    "\n",
    "Next, define $$g \\equiv \\frac{1}{J} Z^{'}\\xi$$\n",
    "\n",
    "Finally, define the GMM objective function as\n",
    "\n",
    "$$ Q(\\theta_B) \\equiv g^{'}Wg $$\n",
    "\n",
    "Any symmetric and positive-definite $W$ gives us the consistent estimates for the parameters. So we use the identity matrix, i.e. $W = I$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def obj(params):\n",
    "    sigma = params[0:5]\n",
    "    alpha = params[5]\n",
    "    delta = contraction(sigma,alpha)\n",
    "    beta = np.dot(prem,delta)\n",
    "    deltam = delta\n",
    "    xi = delta - np.dot(X,beta)\n",
    "    g = (1/nrow)* (np.dot(Z.T,xi))\n",
    "    ob = np.dot(g.T,g)\n",
    "    ob = ob[0,0]\n",
    "    return(ob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we find the parameters $\\sigma$ and $\\alpha$ by solving\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\min_{\\theta_B = (\\sigma,\\alpha)} Q(\\theta_B)\n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Step 0: Load necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from numba import jit\n",
    "import time\n",
    "from numpy.linalg import inv\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Import the data (prepared earlier with the R code above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ns = 1500\n",
    "nrow = data.shape[0]\n",
    "\n",
    "X = data[[\"const\", \"hpwt\", \"air\", \"mpd\", \"size\"]]\n",
    "X = np.asarray(X)\n",
    "sizeX = X.shape[1]\n",
    "Z = data[[\"const\", \"hpwt\", \"air\", \"mpd\", \"size\", \"own_const\", \"own_hpwt\", \"own_air\", \"own_mpd\", \"own_size\", \"all_const\", \"all_hpwt\", \"all_air\", \"all_mpd\", \"all_size\"]]\n",
    "Z = np.asarray(Z)\n",
    "phi = np.dot(Z.T,Z)\n",
    "prem = inv(X.T @ Z @ inv(phi) @ Z.T @ X) @ X.T @ Z @ inv(phi) @ Z.T\n",
    "\n",
    "\n",
    "A = pd.get_dummies(data[\"year\"])\n",
    "A = np.asarray(A, dtype = np.float32)\n",
    "AAT =  np.dot(A,A.T)\n",
    "nyears = A.shape[1]\n",
    "\n",
    "\n",
    "np.random.seed(6128)\n",
    "v = np.random.randn(ns,sizeX)\n",
    "\n",
    "\n",
    "\n",
    "ym = np.array([2.01156, 2.06526, 2.07843, 2.05775, 2.02915, 2.05346, 2.06745, 2.09805, 2.10404, 2.07208, 2.06019, 2.06561, 2.07672, 2.10437, 2.12608, 2.16426, 2.18071, 2.18856, 2.21250, 2.18377])\n",
    "sigma_y = 1.72\n",
    "ym.shape = (nyears,1)\n",
    "np.random.seed(6128)\n",
    "ar = np.random.randn(nyears,ns)\n",
    "y = A @ np.exp(ym + sigma_y*ar)\n",
    "\n",
    "\n",
    "global deltam \n",
    "deltam = np.exp(data[\"logdif\"])\n",
    "deltam = np.asarray(deltam)\n",
    "\n",
    "\n",
    "s_data = np.asarray(data[\"share\"])\n",
    "\n",
    "price = np.asarray(data[\"price\"])\n",
    "price.shape = (nrow,1)\n",
    "\n",
    "\n",
    "tol = 1e-8\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Estimation via minimization of GMM objective function with respect to the parameters $\\sigma$ and $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "init = np.array([3.612, 4.628, 1.818, 1.050, 2.056, 43.501])\n",
    "t0 = time.time()\n",
    "soln = minimize(obj,init,method=\"L-BFGS-B\", tol = 1e-2, options={'disp': True},)\n",
    "elapsed_time = time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 1600.7139041423798\n",
      "GMM objective: 36.4887900203\n",
      "sigma: [ 0.15931316  5.46924628  5.5880774   0.17531137  5.26241119]\n",
      "alpha: 48.0007083577\n",
      "beta: [-5.34348841  5.72331373 -2.25275835  0.23052835  1.43701791]\n"
     ]
    }
   ],
   "source": [
    "print(\"Time elapsed:\",elapsed_time)\n",
    "print(\"GMM objective:\", soln.fun)\n",
    "print(\"sigma: \", abs(soln.x[0:sizeX]),\"\\n\", \"alpha: \", soln.x[sizeX],sep=\"\")\n",
    "print(\"beta:\", (prem @ contraction(soln.x[0:sizeX],soln.x[sizeX])).T[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
